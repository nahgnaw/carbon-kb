CHAPTER 4: Carbon Mineral Evolution
INTRODUCTION
The discovery of the extreme antiquity of specific minerals through radiometric dating (e.g., Strutt 1910), coupled with Norman L. Bowen’s recognition of a deterministic evolutionary sequence of silicate minerals in igneous rocks (Bowen 1915, 1928), implies that Earth’s crustal mineralogy has changed dramatically through more than 4.5 billion years of planetary history.
Detailed examination of the mineralogical record has led to a growing realization that varied physical, chemical, and biological processes have resulted in a sequential increase in diversification of the mineral kingdom.
This diversification has been accompanied by significant changes in the near-surface distribution, compositional range (including minor and trace elements), size, and morphology of minerals (Ronov et al.
1969; Nash et al.
1981; Zhabin 1981; Meyer 1985; Wenk and Bulakh 2004; Hazen et al.
2008, 2009, 2011).
Variation in Earth’s mineralogical character thus reflects the tectonic, geochemical, and biological evolution of Earth’s near-surface environment (Bartley and Kah, 2004; Hazen et al.
2009, 2012; Grew and Hazen 2010a, 2010b; McMillan et al.
2010; Krivovichev 2010; Grew et al.
2011; Tkachev 2011).
The mineral kingdom’s evolutionary narrative shares many features with the increased complexity inherent within other evolving systems, including the nucleosynthesis of elements and isotopes, the prebiotic synthesis of organic molecules, biological evolution through Darwinian natural selection, and the evolution of social and material culture (Hazen and Eldredge 2010).
In particular, well-known biological phenomena such as diversification, punctuation, and extinction appear to be common traits within a wide range of complex, evolving systems.
Perhaps more than any other element, carbon exemplifies these processes of “mineral evolution.” Four episodes outline major events in the mineral evolution of carbon: (1) the synthesis of the first mineral, likely diamond, and perhaps a dozen other “ur-minerals” in the cooling envelopes of active aging stars; (2) the formation of carbon-bearing materials in the condensing solar nebula, as preserved in chondrite and achondrite meteorites; (3) the diversification of carbon mineralogy through physical and chemical processes in the dynamic crust and mantle; and (4) the profound influence of biospheric evolution on Earth’s near-surface carbon mineralogy.
Hazen et al.
(2008) further divided the latter three eras into 10 stages of Earth’s mineral evolution.
Here we review each of these stages of carbon mineral evolution (Table 1).
STAGES OF CARBON MINERAL EVOLUTION
The story of carbon mineralogy began more than 13 billion years ago in the gaseous envelopes of the first generation of large stars.
Prior to the first large energetic stars, perhaps at a time when the universe was a few million years old, there had never been a place that was both dense enough with mineral-forming elements and also cool enough to condense crystals.
But when a dying star explodes into a supernova, or when an asymptotic giant branch star sheds its outer envelope in an intense stellar wind, the star’s element-rich gaseous envelope expands and rapidly cools, the outer layers cooling first.
Hazen et al.
(2008) speculate that the first mineral was diamond (possibly co-precipitated with lonsdaleite), which condensed in carbon-rich zones at temperatures below about 3700°C.
Next came graphite at a slightly cooler 3200°C.
Diamond and graphite were the first of the “ur-minerals”—the dozen or so mineral species that formed prior to the first stellar nebulae, planets, and moons.
In addition to diamond and graphite there are at least two other carbon-bearing ur-minerals, the iron and silicon carbides cohenite and moissanite, as well as possible nano-particles of titanium, iron, molybdenum, and zirconium carbides.
These carbides have crystallization temperatures that are almost as high as diamond, so in the zones of an exploding star where carbon mixed with silicon or iron, carbides would have formed readily.
This relative abundance of carbon-bearing phases among the dozen or so ur-minerals thus reflects the carbon-rich composition of stellar envelopes.
Ur-minerals are concentrated in so-called “dense molecular clouds,” which are vast, cold volumes of the galaxy where hydrogen, helium, and mineral-bearing dust achieve densities of 102 to 104 particles per cubic centimeter, compared to only 1 particle per cubic centimeter in the interstellar voids of the Milky Way galaxy (Williams et al.
2000).
The ur-minerals are present as nanometer- to micron-sized particles in the dust grains, some of which are preserved in the fine-grained matrix of chondritic meteorites.
These grains can be isolated and identified by their anomalous isotopic compositions (Alexander 1990, 1993; Nittler 2003; Messenger et al.
2003, 2006; Stroud et al.
2004; Mostefaoui and Hoppe 2004; Vollmer et al.
2007; Jones 2007).
Second-generation stars and their associated planets arise through gravitational clumping of this primitive nebular material.
Diamond and other carbon-bearing ur-minerals may persist for billions of years, but they are not the dominant C-rich species in molecular clouds.
Astronomical observations employing millimeter-wave spectroscopy reveal distinctive absorption spectra from more than 160 different small molecular species, primarily organic molecules (Allamandola et al.
1989; Ehrenfreund and Charnley 2000; Allamandola and Hudgins 2003; Kwok 2009; for a list see http://en.wikipedia.org/wiki/List_of_interstellar_and_circumstellar_molecules).
Indeed, in the cryogenic temperature regime of the dense molecular cloud, several of the more abundant C-bearing molecules, including CO, CO2, and CH4, may condense onto dust particles to form their own ices, and thus may represent an additional, if ephemeral, source of pre-solar mineralogical diversity.
The Era of Earth’s Accretion
The first stages of Earth’s mineral evolution—diversification beyond the dozen ur-minerals (including the carbon-bearing phases diamond, lonsdaleite, graphite, moissanite, and cohenite; Hazen et al.
2013)—began approximately 4.57 billion years ago and are preserved in the rich record of meteorites.
These diverse objects reveal mineral-forming processes that occurred in the solar nebula prior to the formation of Earth and other planets.
The mineralogical evolution of meteorites can be divided into two distinct stages—first the primitive chondrites, with approximately 60 different primary condensate phases, and then the diverse achondrite meteorites with more than 250 different minerals, which reflect planetesimal differentiation and subsequent alteration by aqueous, thermal, and shock processes (Hazen et al.
2008; McCoy 2010).
Stage 1—Primary chondrite minerals.
Unaltered type 3 chondrite meteorites, which represent the most primitive stage of planetary evolution (McCoy 2010), include a variety of carbon-rich stony meteorites that formed by agglomeration of fine-grained nebular material (Brearley and Jones 1998; Weisberg et al.
2006).
MacPherson (2007) defined “primary” chondrite minerals as phases that formed directly through condensation, melt solidification, or solid-state recrystallization following the earliest stages of nebular heating by the Sun.
These phases include all of the original ur-minerals, but the only new crystalline carbon-bearing phase reported among the approximately 60 known primary chondritic minerals is the iron-nickel carbide haxonite [(Fe,Ni)23C6].
This mineral has not yet been identified in terrestrial rocks and is known only from meteorites (Brearley and Jones 1998) but cohenite (Fe,Ni,Co)3C and other Fe-based carbides are also found in lunar soils and rocks (Goldstein et al.
1976).
Carbon-containing minerals constitute a volumetrically trivial fraction of most chondrites.
Note, however, that type 3 carbonaceous chondrites incorporate all but the most volatile of the 83 stable geochemical elements in roughly their cosmochemical abundances.
Carbon, as the fourth most abundant element in the cosmos (after hydrogen, helium, and oxygen), is thus present in significant concentrations, primarily as complex suites of condensed organic molecules that comprise as much as 5 weight percent of some meteorites (Grady et al.
2002; Sephton 2002; Martins et al.
2007; Herd et al.
2011) and is also particularly widespread as nanodiamond with a mean size ~2.6 nm and abundance reaching 0.15 weight percent (Grady et al 2002).
Schmitt-Kopplin et al.
(2010) report extreme molecular diversity in these meteorites: “tens of thousands of different molecular compositions and likely millions of diverse structures.” These varied molecular species presumably constitute the dominant primordial carbon source that was subsequently processed during the accretion and differentiation of Earth and other terrestrial planets and moons.
Stage 2—Altered chondrite and achondrite meteorites.
The next stage of carbon mineral evolution arose as a consequence of the gravitational accumulation of chondrites into growing planetesimals, with associated alteration by aqueous, thermal, and shock processes.
These modes of mineral alteration are reflected in approximately 150 different mineral species identified in altered chondrites (Rubin 1997a, 1997b; Brearley and Jones 1998; Brearley 2006; MacPherson 2007).
These events, which characterized perhaps the first 10 to 20 million years of the solar nebula, resulted in a number of new carbon-bearing minerals, notably the first carbonates (as well as hydroxide and sulfate minerals) as a consequence of low-temperature (typically < 100°C) aqueous alteration.
Carbonates are especially abundant as veins, isolated grains, and brecciated fragments in the rare CI chondrites, which typically contain ~5 weight percent rhombohedral carbonates, predominantly dolomite, but also calcite (including Mg-, Fe-, and Mn-rich varieties), magnesite, and siderite (Fredriksson and Kerridge 1988).
Carbonates are also common in CM chondrites; calcite predominates in these materials, although dolomite and minor aragonite are also known (Kerridge and Bunch 1979; Barber 1981).
As planetesimals grew to diameters greater than 100 kilometers, they experienced compaction, melting, and differentiation into an iron metal-rich core and silicate mantle.
Mineralogical diversity increased as a result of variable oxygen fugacity, volatile content, aqueous fluid pH and salinity, variable heat sources, and impact events of ever greater intensity (McCoy et al.
2006).
Additional diversity was driven by the fractionation of silicate melts by partial melting, crystal settling, and potential liquid immiscibility (Shukolyukov and Lugmair 2002; Wadhwa et al.
2006).
Diamond, lonsdaleite, and graphite, and the iron-nickel carbides cohenite and haxonite, represent important accessory phases in many iron meteorites, and reflect the fractionation of at least some carbon into reduced, refractory core minerals.
Note, however, that the total carbon content of iron meteorites rarely exceeds 0.1 weight percent (e.g., Jarosewich 1990).
Impact shock metamorphism may have also acted to modify significantly some carbon minerals (Langenhorst and Deutsch 2012).
For example, the shock transition of graphite to diamond or lonsdaleite had been inferred by a number of researchers (Hanneman et al.
1967; Masaitis et al.
1972; Carlisle and Braman 1991; Russell et al.
1992; Ross et al.
2011) prior to direct observation of the frozen solid-state transformation in samples from meteor craters (Langenhorst et al.
1999, El Goresy et al.
2001).
In a number of these shocked samples, diamond/lonsdaleite-type phases with a disordered stacking sequence preserve the hexagonal crystal form of graphite.
Carbonate minerals are also known to express a range of shock metamorphic textural changes and, ultimately, volatilization under the influence of hypervelocity impacts, notably reflected in the release of CO2 (Martinez et al.
1998; Agrinier et al.
2001; Jones et al 2000; Ivanov and Deutsch 2002; Deutsch and Langenhorst 2007).
However, no novel carbonate minerals associated with shocked meteorites have been documented.
Of the total of approximately 250 mineral species that are known to occur in all types of meteorites (e.g., Mason 1967; Rubin 1997a, 1997b; Brearley and Jones 1998; Gaffey et al.
2002; MacPherson 2007), only about a dozen are carbon bearing.
Additional carbon mineral diversification had to await significant reworking of Earth’s outer layers by a variety of physical, chemical, and biological processes.
The Era of Crust and Mantle Processing
The billion years following planetary accretion was a time of intense reworking of Earth’s outer gaseous, liquid, and solids layers.
A succession of giant impacts, punctuated by the Moon-forming collision of Mars-sized Theia at ~4.55 Ga, must have had a profound influence on Earth’s near-surface mineralogy.
The planet’s volatile content, including carbon, may have been drastically reduced and, for a time, an ocean of magma encircled the globe (Tonks and Melosh 1993; Ruzicka et al.
1999; Touboul et al.
2007).
The subsequent three stages of Earth’s mineral evolution reflect the influences of a complex combination of igneous, metamorphic, and tectonic processes.
Stage 3—Igneous rock evolution.
Following Earth’s accretion, and again for perhaps half a billion years following the Moon-forming event, the mineralogical diversity of Earth evolved primarily by crystallization of igneous rocks (Bowen 1915, 1928), supplemented by a steady bombardment of asteroidal and cometary material.
However, many details of those processes, especially the composition and differential role of volatiles that would contribute to or even dominate formation of the oceans, atmosphere, and near-surface fluids (the “exosphere”), remain uncertain.
Carbon does not play a significant role in Bowen’s classic reaction series, nor is it obvious how the carbon content of primitive volatiles affected the evolution of magmas through fractional crystallization, crystal-liquid separation, and other physical and chemical igneous processes (though see Manning et al.
2013; Ni and Keppler 2013; Jones et al.
2013; Sephton and Hazen 2013).
We therefore have little understanding of the processes that first generated significant amounts of carbon minerals or carbonate melts at or near Earth’s surface, and what carbon minerals may have been present.
Meteorites and comets would have continued to provide a small but steady supply of a few carbon minerals to Earth’s surface: graphite, nano-diamonds, moissanite, iron carbides, and minor carbonates, along with much more significant quantities of carbon dioxide and varied organic species.
The first carbon minerals to form at or near Earth’s surface seem likely to have been restricted to graphite through subsurface reactions of reduced C-O-H fluids (Rumble and Hoering 1986; Rumble et al.
1986; Manning et al.
2013) and the rhombohedral carbonates, predominantly in the Mg-Ca-Fe-Mn system (i.e., magnesite, calcite, siderite, dolomite, ankerite, rhodochrosite, and kutnohorite; Hazen et al.
2013).
One possibility for Earth’s Hadean and Archean Eon carbon mineralization is the generation of carbonate melts, perhaps through immiscibility in the upper mantle.
However, no evidence for Paleoarchean (much less Hadean) carbonatites is known to have survived (Jones et al.
2013).
Carbonatites appear to have increased steadily in volume through Earth history from the 2.609 Ga ± 6 Ma (Neoarchean) Siilinjärvi carbonatite to the present (Veizer et al 1992; Jones et al.
2013), with the majority of older (Proterozoic and Phanerozoic Eon) carbonatites preserved as intrusive bodies.
This temporal distribution may reflect a preservational bias resulting from the rapid chemical degradation of carbonatite lava flows.
Only one carbonatite volcano, Oldoinyo Lengai in Tanzania, is active today, and its carbonate mineralogy alters rapidly when in contact with the atmosphere, because the alkali carbonates are water-soluble (Genge et al.
2001).
Such rapid weathering, however, would source an array of variably alkaline fluids, such as those that drain into alkaline Lake Natron, which could result in precipitation of carbonate mineral salts.
Indeed, the major hurdle in documenting Earth’s carbon mineral evolution prior to the Neoarchean (~2.8 Ga) is the extensive alteration, and general rarity, of Earth’s early rock record (e.g., Papineau 2010).
No outcrops with an unambiguous age older than about 4 billion years survive.
Even if relatively unaltered early Hadean samples are found, for example in the guise of Earth meteorites on the Moon (Armstrong et al.
2002; Chapman 2002; Jakosky et al.
2004), it is unlikely that carbon minerals will be found.
Consequently, models of the genesis of Earth’s earliest carbonates must remain speculative.
Barring a significant role of igneous carbonate production, however, aqueous precipitation appears to be the most likely source of Earth’s earliest carbonates.
Evidence for early oceans may be found in the oldest known fragments of Earth, detrital zircon grains with ages of 4.4 to 4.0 Ga extracted from Archean quartzites in Western Australia.
These zircon crystals preserve oxygen isotope ratios characteristic of relatively cool, wet host rocks—possibly evidence for early granitic continental crust (Harrison et al.
2005; Cavosie et al.
2005; Hopkins et al.
2008, 2010) or pre-continental mafic to ultramafic crust (Shirey et al.
2008).
Wet crust also implies an early ocean, perhaps by 4.4 Ga.
Such an early appearance of the hydrosphere is consistent with rapid volcanic outgassing and fluid-rock interactions that would have released initial atmospheric components, predominately N2, CO2, and H2O, with minor H2S (e.g., Holland 1984).
The immediate mineralogical consequence of these interactions would have been significant serpentinization in Earth’s mafic crust, as well as the first significant production of clay minerals, with magnesite as a possible accessory mineral.
An additional consequence of early crustal weathering may have been a rapid increase in the salinity of the warm, slightly acidic oceans (Hardie 1996; 2003; Lowenstein et al.
2001; Dickson 2002).
Under such conditions, the pH and ionic composition would have been the most important factors that might have controlled carbonate precipitation in the Hadean or Paleoarchean oceans.
The pH of these most ancient environments would have been a critical constraint on carbonate formation, because the speciation of carbon dioxide in natural waters is strongly governed by pH.
Under even mildly acidic conditions, carbon dioxide is present primarily as aqueous CO2 and as carbonic acid, which would have inhibited precipitation of carbonate minerals.
Another critical constraint on carbonate precipitation would have come from the ionic composition of Earth’s surface fluids.
One can speculate that strongly reducing conditions of the earliest Earth would have resulted in copious amounts of reduced iron, such that siderite may have been the primary carbonate mineral in both terrestrial and marine settings.
Siderite formation points to at least four specialized chemical conditions: (1) the presence of aqueous Fe2+; (2) anoxic ocean water with oxygen fugacity < 10-68 to prevent iron removal by precipitation of ferric iron oxide-hydroxides; (3) low sulfide and sulfate ions, which would otherwise lead to pyrite precipitation; and (4) dissolved aqueous HCO3- (Moore et al.
1992; Ohmoto et al.
2004).
Alternatively, under early Earth’s substantially higher heat flows, both oceanic basalts and their hydrothermal weathering products would have contained substantially more magnesium, suggesting a potentially greater importance of magnesite.
In fact, Mozley (1989) showed that Archean siderite compositions appear to reflect faithfully the aqueous environments in which they form.
Fresh water precipitation yields relatively pure FeCO3, whereas formation in a saline environment produces siderite with significant Mg and Ca substitution for Fe—compositional effects that reflect the differences in ionic composition of terrestrial and marine waters.
Stage 4—Granitization.
Carbon mineral evolution must have been significantly influenced by the gradual formation of cratons, with their suites of relatively low-density siliceous rocks generated by eutectic melting of mafic and ultramafic lithologies, including tonalite-trondhjemite-granodiorite (TTG), granodiorite-granite-monzogranite (GGM), and high-K syenite-granite (SG) suites (Smithies and Champion 2000; Smithies et al.
2003; Zegers 2004).
The nature of this earliest continental crust probably differed both petrologically and tectonically from that of today (see, however, Hopkins et al.
2008, 2010).
Tectonic activity prior to 3.5 Ga may have been dominated by vertical processes through deep mantle plumes, rather than today’s predominantly lateral tectonics (e.g., Van Kranendonk 2011).
Surface relief of the thin, hot, principally basaltic crust would have been correspondingly low, and the exposed surface was likely subject to both intense weathering and intense mechanical erosion (Dott 2003), notably from rapid cycling (< 8 hours) of tides generated by the much closer Moon (Lathe 2006; Varga et al.
2006).
In such an environment, significant terrestrial deposition of carbonate minerals seems unlikely.
An important mineralogical consequence of granitization was the generation of eutectic fluids concentrated in rare pegmatophile elements and the eventual deposition of complex pegmatites.
These processes of element selection and concentration are likely to have taken considerable time (e.g., Grew and Hazen 2009, 2010b); one of the oldest known complex pegmatite, the Tanco pegmatite in Manitoba, Canada, is 2.67 billion years old (London 2008).
Carbonate minerals are not dominant species in complex pegmatites, but a few rare species including niveolanite [NaBeCO3(OH).2H2O] and zabuyelite (Li2CO3) exemplify the striking mineral diversification that is possible with the formation of complex pegmatites.
Stage 5—Plate tectonics.
By 3.0 Ga, or perhaps significantly earlier, lateral tectonics and continent formation had begun on Earth (e.g., Harrison et al.
2005; Workman and Hart 2005; Shirey et al.
2008; Silver and Behn 2008; Shirey and Richardson 2011; Van Kranendonk 2011).
The initiation of plate tectonics, especially the beginning of large-scale subduction and the associated crustal reworking and arc volcanism, had significant mineralogical consequences.
On the one hand, large-scale hydrothermal reworking of the crust and upper mantle associated with volcanogenic processes at subduction zones and ridges generated the first massive sulfide deposits and associated precious metal concentrations (Sangster 1972; Hutchinson 1973).
These ore bodies arise as hydrothermal solutions interact with many cubic kilometers of rock (Barnes and Rose 1998)—fluids that selectively dissolve and concentrate incompatible elements and thus lead to novel mineralization.
On the other hand, this modern plate tectonic cycle also generated, for the first time, buoyant continental crust that resulted in substantial amounts of subaerially exposed crust, as well as potentially extensive shallow marine continental shelves.
The combination of these factors may have, in turn, fundamentally changed carbonate mineralization in the marine realm.
At atmospheric carbon dioxide concentrations potentially 100 times present atmospheric levels (Kasting 1987; Kasting et al.
1993) the acidity of terrestrial rainwater would have contrasted sharply with that of marine environments, whose pH would have been buffered by hydrothermal weathering reactions at mid-ocean ridges.
Subaerially exposed continents would have experienced extensive chemical weathering and the transport of these weathering products to the shallow ocean.
Because chemical weathering of silicate minerals produces bicarbonate (HCO3-) as the conjugate base to carbonic acid, extensive continental weathering would result in enhanced delivery of bicarbonate to the oceans.
Enhanced delivery of bicarbonate would have come at the expense of the acidity generated by equilibration of natural waters with elevated atmospheric carbon dioxide.
Neutralization of terrestrial waters through chemical weathering and the subsequent delivery of bicarbonate to the marine system would have acted as an effective buffer of marine pH, and would have allowed marine carbonate saturation to increase to the extent that it was balanced by marine alkalinity.
Along with increased carbonate saturation state, another consequence of cratonization was the generation, perhaps for the first time, of extensive shallow marine shelves.
These shallow marine environments would have experienced systematically greater degrees of solar heating and wave agitation, both of which drive local carbonate saturation states higher via degassing of carbon dioxide.
In epicratonic environments, which experience reduced advective interchange with the open ocean, evaporative concentration of shallow marine waters can further raise carbonate saturation states.
Together, these processes would have yielded, perhaps for the first time, an abundance of environments conducive to carbonate mineral formation.
Finally, it was within these shallow marine environments that light-dependent (i.e.
photosynthetic-bearing) benthic microbial mats (Noffke 2011)—and their complex relationship with both carbonate mineralization and carbon species within the ocean-atmosphere system—began to flourish, forever changing Earth’s carbon cycle (Allwood et al.
2009; Dupraz et al.
2009; Zerkle et al.
2012).
Another possible mineralogical innovation associated with the stabilization of continental shelves may have been the first extensive deposition of methane hydrates (Hazen et al.
2013).
This as yet unnamed clathrate mineral is today one of the crust’s most abundant and widely distributed carbon minerals (Kvenvolden 1995).
Most researchers cite methanogenic microbes and the degradation of buried organic matter as the principal sources of methane, though some advocates postulate a significant abiotic mantle source for some crustal methane deposits (Gold 1999; Kenney et al.
2001; Kutcherov et al.
2002; Sephton and Hazen 2013).
Consequently, methane hydrate may have first occurred early in Earth’s history, perhaps as early as stage 3.
The most important potential consequences of plate tectonics on carbon mineralogy relate to subduction of carbon, notably carbon-rich sediments.
The sequestration of carbonates and organic matter has undoubtedly played, and continues to play, a major and evolving role in Earth’s carbon cycle (Hayes and Waldbauer 2006; Kah and Bartley 2011; Dasgupta 2013).
The Archean Eon saw a significantly smaller volume of carbonate mineralization than today, but what there was likely dissociated during subduction as a consequence of the steeper geothermal gradient (e.g., Zhu and Ogasawara 2002; Manning et al.
2013; Jones et al.
2013).
However, the lower temperature gradient of today’s subduction zones may preclude carbonate dissociation, with limestone and dolomite recycled into Earth’s deep interior (Kraft et al.
1991; Gillet 1993; Seto et al.
2008).
The Era of the Evolving Biosphere
The evolution of Earth’s near-surface carbon mineralogy, notably the diversity and distribution of carbonate minerals, is intertwined with the origin and evolution of life.
In this respect, the co-evolving geosphere and biosphere transformed Earth.
Three principal sequential episodes frame this story.
With the origins of life and the rise of chemolithoautotrophic microbial communities by ~3.5 Ga, Earth’s surface environments saw an acceleration of certain mineral-forming processes, notably our earliest evidence for marine carbonate precipitation.
Then, coincident with increased continental growth, the rise of photosynthetic organisms saw an increase in both organic and inorganic carbon formation, which culminated in the Great Oxidation Event (GOE) at ~2.4 Ga.
The GOE represents a fundamental shift in the oxidation state of Earth’s surface that dramatically altered the near-surface geochemical environment and ultimately led to thousands of new mineral species.
The GOE also marked the onset of a nearly 1.5 billion year period of progressive oxygenation of Earth’s surface that highlights the complexity of physical, chemical, and biological interactions during carbonate mineral formation.
Finally, the innovation of skeletal biomineralization at ~0.6 Ga irreversibly altered the carbon cycle and, consequently, the nature and distribution of carbonate minerals.
Stage 6—The origins of life and the rise of chemolithoautotrophs.
Life emerged on Earth by the Paleoarchean Era (> 3.5 Ga); however, the influence of life on Earth’s mineral diversity appears to have been minimal prior to the Mesoproterozoic Era (~1.8 to 1.6 Ga).
The earliest cellular consortia were chemolithoautotrophs that exploited redox couples already present in Earth’s dynamic near-surface geochemical environment.
Life appears to have survived by accelerating favorable oxidation-reduction reactions that were otherwise kinetically inhibited.
It is important to bear in mind that true catalysts allow reactions that are thermodynamically favorable to take place despite kinetic barriers to their occurrence.
Catalysts (including chemolithoautotrophic microbes) thus speed the approach to thermodynamic equilibrium, but do not alter that final equilibrium.
Banded iron formations (BIFs) may represent the most dramatic of these microbial precipitates (e.g., LaBerge 1973; Anbar and Holland 1992; Konhauser et al.
2002, 2007; Kappler et al.
2005).
BIFs, which constitute a major source of iron ore, are among the earliest Archean sedimentary formations (as old as 3.85 Ga) and they occur in pulses through the Archean-Proterozoic boundary at ~2.45 Ga (Isley and Abbott 1999; Klein 2005).
It should be noted, however, that some BIFs may have an abiotic origin through hydrothermal processes (Jacobsen and Pimentel-Close 1988; Kimberley 1989; Bau and Möller 1993; Klein 2005).
In any event, the majority of BIFs appear to have precipitated from colloidal or gel SiO2 that contained aqueous ferric and ferrous iron as well as dissolved Na+, K+, Mg2+, Ca2+, and HCO3- (Klein 1974).
Redox and pH variations led to three contrasting mineralogies: a quartz-hematite-magnetite oxide facies, a pyrite-marcasite-pyrrhotite sulfide facies, and a siderite-ankerite-dolomite-calcite carbonate facies.
Oxide facies dominate Archean BIFs, though sulfide and carbonate facies also occur (e.g., Dymek and Klein 1988; Dauphas et al.
2007).
A number of lines of evidence point to an anoxic surface environment prior to the Great Oxidation Event at ~2.4 Ga (Holland 1984; Farquhar et al.
2001; Hazen et al.
2008; Sverjensky and Lee 2010).
Among these many lines of evidence for Archean anoxia are: (1) unweathered detrital grains of such redox-sensitive minerals as pyrite, siderite, and uraninite (UO2) in South African and Canadian river deposits (Rasmussen and Buick 1999; England et al.
2002); (2) the absence of a cerium anomaly in the 2.5 Ga Pronto paleosols (Murakami et al.
2001); (3) the absence of Fe3+ hydroxides in paleosols older than 2.3 Ga (Rye et al.
1995; Holland and Rye 1997); and (4) mass independent fractionation of sulfur isotopes (e.g., Farquhar et al.
2000, 2007; Ono et al.
2003; Papineau et al.
2007).
As noted by Sverjensky and Lee (2010), significant near-surface Fe2+ provided an effective hematite-magnetite redox buffer for much of Earth’s earliest history—a buffer that maintained the surface oxygen fugacity at ~10-72 (Figure 1).
The near-surface precipitation of ferrous iron carbonates, such as siderite-ankerite deposition exemplified by early Archean, highly metamorphosed calc-silicate deposits in >3.7 Ga rocks of Greenland (Rose et al.
1996; Dymek and Klein 1988) and northern Quebec (Dauphas et al.
2007), requires a reducing environment with an STP oxygen fugacity < 10-68 at assumed values of CO2 fugacity < 10-2 (Figure 2).
Siderite and ankerite precipitation are thus consistent with other evidence for a highly reducing near-surface Archean environment.
Note, however, that siderite is lacking in Archean paleosols that are contemporaneous with marine Fe2+ carbonate precipitation (Rye et al.
1995).
This absence of iron carbonates may reflect relatively low concentrations of atmospheric CO2.
Note, however, that other researchers suggest that atmospheric CO2 concentrations were significantly greater than today and experienced significant fluctuations prior to 2.5 Ga (e.g., Holland 1984; Rye et al.
1995; Sagan and Chyba 1997; Kaufman and Xiao 2003; Kah and Riding 2007).
Alternatively, Ohmoto et al.
(2004) cite the absence of paleosol siderite as possible evidence for trace levels of atmospheric O2, which would have prevented the formation of siderite in soils, even under high CO2 concentrations.
Indeed, trace element data from black shale deposits suggests that photosynthesis in near-shore (and presumably terrestrial) environments may have acted as local sources of biospheric oxygen in an otherwise anoxic Archean world (Kendall et al.
2010).
It remains unresolved the extent to which biological activity influenced carbonate mineral formation in the Archean Eon.
Oxygenic photoautotrophs, such as cyanobacteria, are recognized for their ability to raise local pH and carbonate saturation and thereby actively promote carbonate mineral precipitation (Thompson and Ferris 1990; Kranz et al.
2010).
The evolution of oxygenic photoautotrophs, however, appears not to have occurred until some time after 2.7 Ga (Rasmussen et al.
2008).
Similarly, changes in carbonate alkalinity associated with bacterial reduction of Mn and sulfate that promote carbonate mineral precipitation (Froelich et al.
1979; Canfield and Raiswell 1991) would not be expected until approximately 2.5 Ga, with the development of at least local oxygen oases and their associated redox gradients (Kaufman et al.
2007; Anbar et al.
2007; Kendall et al.
2010).
Microbial influence on Archean carbonate mineralization is therefore more likely to reflect anoxygenic photoautotrophy (Olson and Blankenship 2004; Westall et al.
2006; Johnston et al.
2009) or methanogenesis (Battistuzzi et al.
2004; Ueno et al.
2006).
Although either anoxygenic photoautotrophy or methanogenesis is capable of promoting increased carbonate saturation (Kenward et al.
2009; Bundeleva et al.
2012), experimental approaches suggest that active mineral precipitation within microbial mats requires not only metabolically increased carbonate saturation, but also the liberation of EPS-bound Ca during biofilm decomposition (Dupraz et al.
2009).
Little evidence survives of significant non-ferroan carbonate precipitation prior to about 3.5 Ga, when a variety of stromatolitic forms provide unambiguous evidence for at least limited carbonate biomineralization (Walter et al.
1980; Lowe 1980; Buick et al.
1981; Byerly et al.
1986; Walter 1994; Grotzinger and Knoll 1999; Frankel and Bazylinski 2003; Allwood et al.
2006; Van Kranendonk 2006, 2007).
However, these deposits are highly localized and extensive sedimentary carbonate deposits are rare until after 3.0 Ga.
Even after the appearance of the earliest large-scale carbonate deposits in the ~2.95 Ga Steep Rock Group of northwestern Ontario (Jolliffe 1955; Wilks and Nisbet 1988; Tomlinson et al.
2003), nearly 250 million years passed before the first laterally extensive carbonate platforms at ~2.7 Ga (Sumner 1997).
Increasing carbonate platform development in the late Archean Eon may reflect increased cratonization and the development of widespread, shallow marine environments with highly elevated carbonate saturation.
Indeed it is these early epi- to pericratonal environments that preserve both neomorphic crystal textures characteristic of aragonite precipitation (Grotzinger 1989; Sumner and Grotzinger 2004) as well as the oldest known primary aragonite, which occurs as nanocrystals within dolomitic stromatolites of the 2.72 Ga Tumbiana Formation, Western Australia (Lepot et al.
2008).
Carbonate mineral precipitation within these strongly supersaturated waters still may have been limited by regionally low oxygen and elevated concentrations of Fe2+, which can effectively inhibit carbonate nucleation (Sumner and Grotzinger 1996b).
Whereas microbial consortia may have played a relatively minor role in the precipitation of carbonates in the Paleo- and Mesorchean Eras, biological organisms appear to have played an increasing role in the Neoarchean Era, prior to the Paleoproterozoic Great Oxidation Event.
The appearance of extensive Neoarchean carbonate platforms appears to have promoted marine fluids with elevated carbonate saturation.
At this same time, the evolution of oxygenic photosynthesis would have led to considerably heterogeneity in benthic redox conditions (Kaufman et al.
2007; Anbar et al.
2007; Kendall et al.
2010).
Critically, even small amounts of environmental oxygenation would have reduced the inhibitory effect of Fe2+ within the water column while driving increased microbial reduction of oxidized phases, which would have further enhanced local carbonate saturation.
Evidence for a diverse set of microbe-mineral interactions at this time comes, in part, from petrographic observations in the ~2.52 Ga Cambellrand platform that record preferential nucleation of fibrous marine carbonate on specific microbial mat elements (Sumner 1997).
While microbial consortia may have played a localized role in the precipitation of carbonates, life played a relatively minor role in modifying Earth’s Archean carbon mineralogy.
That situation changed dramatically following global-scale biologically mediated changes in atmospheric chemistry of the Paleoproterozoic Great Oxidation Event.
Stage 7—Photosynthesis and the Great Oxidation Event.
Numerous lines of evidence point to a dramatic rise in atmospheric oxygen concentrations from complete anoxia to perhaps a few percent of modern levels at approximately 2.4 to 2.25 Ga (Canfield et al.
2000; Kump et al.
2001; Kasting 2001; Kasting and Siefert 2002; Towe 2002; Holland 2002; Bekker et al.
2004; Barley et al.
2005; Catling and Claire 2005; Papineau et al.
2005, 2007; Kump and Barley 2007).
This dramatic and relatively sudden change in atmospheric oxygenation marks the rise of oxygenic photosynthesis by cyanobacteria, an increased redox cycling within microbial mats, and is reflected in an unprecedented increase in the diversity of marine carbonate formation (Grotzinger and Knoll 1999; Melezhik et al.
1997).
Oxygenation of Earth’s surface environments is characterized by large-scale deposition of oxidized hematite-bearing BIFs as well as massive manganese oxide deposits in marine environments, some of which are accompanied by the Ca-Mn carbonate kutnohorite as found in quantity at the Mesoproterozoic Kalahari manganese fields, North Cape province, South Africa  (Leclerc and Weber 1980; Dasgupta et al.
1992; Roy 2006).
The Paleoproterozoic rise in atmospheric oxygen (and concomitant gradual oxygenation of near-surface groundwater) likely represents the single most important event in the diversification of Earth’s carbon mineralogy (Hazen et al.
2008; McMillan et al.
2010).
Prior to 2.4 Ga, anoxic environments at Earth’s surface precluded the formation of many carbonate species.
Consider the familiar hydrated copper carbonates azurite [Cu3(OH)2(CO3)2] and malachite [Cu2(OH)2CO3].
Calculations of their stability fields as a function of fO2 and fCO2 (Figure 3) reveal that these (and many other) divalent copper minerals require fO2 > 10-43 at STP at presumed values of CO2 fugacity < 10-2 (e.g., Garrels and Christ 1965).
However, prior to ~2.4 Ga the near-surface environment was constrained by the hematite-magnetite buffer with fO2 ~ 10-72 (Figure 1).
Consequently, neither azurite nor malachite was stable prior to the Great Oxidation Event.
Similar arguments may be applied to the numerous carbonates of U6+, Mo6+, Hg2+, and other redox sensitive cations (Hazen et al.
2009, 2012; McMillan et al.
2010).
It is interesting to note that most of the thousands of new mineral phases, including more than 100 new carbonate minerals that are associated with near-surface oxidation, did not first appear immediately following atmospheric oxidation at 2.4 Ga.
In fact, recent surveys of the first appearances of the minerals of Be, B, and Hg point to a relatively protracted interval between 2.4 and 1.8 Ga with few new minerals, followed by a surprising pulse of mineral diversity between 2.0 and 1.8 Ga. Hazen et al.
(2012) attributed this feature to mineralization associated with the assembly of the Columbia supercontinent, possibly coupled to a protracted interval of gradual subsurface oxidation (McMillan et al.
2010).
Although oxygenation of surface environments remained limited at this time, as evidenced by biomarker evidence supporting photic zone anoxia (Brocks et al.
2005), this interval also corresponds to expansion of carbonate-hosted lead-zinc deposits, which reflect increased oxidative weathering, delivery of sulfate to, and bacterial reduction within, marine systems (Lyons et al.
2006).
Stage 8—The intermediate ocean.
The story of marine carbonate minerals in the aftermath of the GOE is complex and largely one of oceanic heterogeneity.
The GOE represents a critical threshold beyond which Earth surface environments became oxidizing rather than reducing.
Yet a second threshold of oxygenation—one necessary to bring a large portion of the oceanic substrate into the oxidative realm—may not have been passed until perhaps the final days of the Proterozoic Eon.
In the intervening time, marine systems experienced a nearly 2 billion year interval in which Earth’s surface experienced only gradual increases in oxygenation (Kah and Bartley 2011), potentially coupled with conjugate decreases in atmospheric CO2 concentration (Bartley and Kah 2004).
Within the marine realm, environmental evolution was reflected in (1) limited oxygenation of surface oceans (Brocks et al.
2005; Blumenberg et al.
2012); (2) increased riverine delivery of sulfate to surface oceans (Kah et al.
2004) and its subsequent microbial reduction, which formed broad regions of euxinia, particularly in near shore, shallow marine environments (Shen et al.
2002; Poulton et al.
2004; Lyons et al.
2009); and (3) the retention of perpetually anoxic, potentially ferruginous, deep oceans (Planavsky et al.
2011).
Together, restriction of oxygenated environments and development of strong redox gradients resulted in both spatial and temporal heterogeneity within the oceans.
Spatial heterogeneity was also facilitated by warm, non-glacial conditions of the Mesoproterozoic Era (1.6-1.0 Ga) and the assembly of the supercontinent of Rodinia, both of which favored globally high sea levels that formed vast, shallow, epicratonic seaways.
Reduction of advective mixing between these vast epicratonic seaways and open ocean environments, in combination with their low water volumes and a generally long residence time for fluids, produced localized environments that could show rapid chemical change in response to regional hydrodynamic conditions, thereby enhancing the heterogeneity of marine environments.
Furthermore, within these varied environments, redox gradients were exploited by largely prokaryotic ecosystems that included both oxygenic and anoxygenic photosynthesizers (Dutkiewicz et al.
2003; Brocks et al.
2005; Blumenberg et al.
2012), a range of bacterial sulfate reducers and disproportionating sulfur oxidizers (Canfield and Teske 1996; Johnston et al.
2005), as well as an active methanogenic community (Guo et al., 2012).
The Mesoproterozoic Era also saw the appearance and diversification in some marine environments of both unicellular and multicellular algae (Butterfield et al.
1990; Javaux et al.
2004; Knoll et al.
2006).
Such biological diversification, of planktic algae in particular, appears to have played a critical role in the reorganization and potential stability of the marine carbon cycle (Ridgwell et al.
2003; Bartley and Kah 2004).
Ultimately, this confluence of physical, chemical, and biological conditions resulted in a global ocean in which a broad range of local parameters could act individually or in concert to overcome kinetic barriers to carbonate precipitation.
As a result, the heterogeneity of Mesoproterozoic oceanic environments is marked by equally heterogeneous carbonate mineralization.
Perhaps most striking—and in need of much further study—is the observation that biological and chemical heterogeneity of Mesoproterozoic oceans appear to have been reflected in a discrete partitioning of both carbonate crystal form and carbonate mineralogy.
Current investigations suggest that seafloor precipitation of fibrous aragonite (Figure 4a), which is common in Archean and Paleoproterozoic oceans, experienced a gradual restriction to peritidal, evaporative environments (Kah and Knoll 1996; Kah et al.
2012), where evaporative concentration may have greatly increased local saturation states.
Meanwhile, herringbone calcite (Figure 4b) experienced a progressive restriction to deeper water environments.
Herringbone calcite is an unusual carbonate morphology, believed to represent neomorphic replacement of high-magnesium calcite (Grotzinger and Kasting 1993), that consists of elongate crystals in which the c-axis rotates throughout growth, from parallel to perpendicular to crystal elongation.
This unusual mode of crystal growth is most prevalent within Archean sea floor precipitates (Sumner and Grotzinger 1996a, 1996b) and has been attributed both to inhibitory crystal growth effects of Fe2+ under conditions of regional anoxia (Sumner and Grotzinger 1996b) and to increased crystal growth rates associated with the presence of locally elevated concentrations of dissolved inorganic carbon derived from re-mineralized organic matter (Tourre and Sumner 2000).
In the Mesoproterozoic Era, extensive precipitation of herringbone carbonate is restricted to deeper water facies, with its presence in platform deposits closely associated with transgressive surfaces (Kah et al.
2006, 2009, 2012).
Combined, these observations suggest that herringbone carbonate mineralization is strongly linked to oceanic redox gradients.
Between these shallow- and deep-water environments, carbonate mineralization appears to be more strongly linked to microbial activity, with finely crystalline calcite precipitates forming both within the water column and within benthic microbial mats.
Microbial activity even appears to have fostered the formation of unique carbonate crystal morphologies that are preserved nearly exclusively within the Mesoproterozoic Era.
“Molar-tooth” structure is an enigmatic, Precambrian carbonate fabric that consists of variously shaped voids and cracks that formed at or near the sediment-water interface and were filled with a uniform, equant microspar (Furniss et al.
1998; James et al.
1998; Bishop and Sumner 2006; Bishop et al.
2006; Pollock et al.
2006), referred to as molar-tooth microspar (Figure 4c).
Molar-tooth cracks likely formed via gas-sediment interaction during the microbial decomposition of sedimentary organic material (Furniss et al.
1998; Pollock et al.
2006).
Void-filling microspar, which consists of uniformly sized spheroidal crystals and associated syntaxial overgrowths, is consistent with formation via spontaneous carbonate nucleation associated with the interaction of pore fluids enriched in dissolved organic matter with the infiltration of supersaturated seawater (Pollock et al.
2006).
Although molar-tooth microspar has been suggested to have initially formed as either aragonite (Bishop and Sumner 2006) or vaterite (Furniss et al.
1998), experimental precipitation under Proterozoic-like conditions (elevated carbonate saturation and low sulfate) produces a mixture of amorphous calcium carbonate (ACC) with minor vaterite (Goodman and Kah 2007).
Stage 9—The snowball Earth.
Characteristic heterogeneity in carbonate mineral formation continued into the Neoproterozoic, where marine ocean chemical environments experienced additional modification via continued biotic evolution and as a consequence of dramatic climate fluctuations between about 0.75 and 0.54 Ga. During the waning of the Proterozoic Eon, Earth environments are marked by at least three episodes of global glaciation (Hoffman et al.
1998; Kennedy et al.
1998).
Evidence includes (1) low-latitude glacial deposits at or near sea level (Young 1995; Hoffman and Prave 1996; Halverson 2005; Evans 2006); (2) extreme carbon and sulfur isotope excursions (Hoffman et al.
1998; Gorjan et al.
2000; Hurtgen et al.
2005; Fike et al.
2006); (3) deposition of cap carbonates with abundant bottom-nucleated aragonite fans overlying glacial diamictites (Fairchild 1993; Kennedy 1996; Halverson et al.
2005); (4) distributions of Fe minerals (Young 1976; Canfield et al.
2007); and (5) Ir anomalies representing glacial cumulates (Bodiselitsch et al.
2005).
According to the “snowball Earth” scenario (Kirschvink 1992; Hoffman and Schrag 2000), glacial cycles occurred when continents were clustered near the equator so that snow cover triggered runaway albedo feedback, possibly amplified by decreases in atmospheric CO2 (Ridgwell et al.
2003; Donnadieu et al.
2004).
During at least three snowball intervals of approximately 10 million years duration, surface-weathering processes decreased while atmospheric CO2 concentrations from volcanoes increased significantly (Caldeira and Kasting 1992; Pierrehumbert 2004).
Eventually, increased CO2 led to rapid greenhouse warming, ice melting, and rapid deposition of thick aragonite crystal fans, suggesting highly supersaturated seawater.
It is intriguing that melting of methane hydrates (Hazen et al.
2013) and the consequent release of methane may have provided a mineralogical accelerant to this period of positive climatic feedback (Jacobsen 2001).
Glacial melting in the Neoproterozoic Era was accompanied by a significant rise in atmospheric oxygen to perhaps 15 percent of today’s value (Fike et al.
2006; Canfield et al.
2007).
Resultant increases in clay mineral formation may have had an important influence on the carbon cycle and thus an indirect effect on carbon mineralogy.
Atmospheric CO2 enrichment, greenhouse warming, and oxygenation combined to enhance production of clay minerals in soils, for example by the bio-weathering of feldspar and mica (Schwartzman and Volk 1989; Paris et al.
1996; Barker et al.
1998; Ueshima and Tazaki 1998; Tazaki 2005).
Accordingly, Kennedy et al.
(2006) describe significant increases in Neoproterozoic clay mineral deposition.
Increased clay mineral production may have enhanced sequestration of organic carbon, which readily adsorbs onto clay surfaces and can thus be buried in marine sediments (Hedges and Kiel 1995; Mayer et al.
2004).
Because the oxidation of organic carbon provides a major sink for atmospheric oxygen, this clay-mediated burial of organic carbon may have indirectly contributed to a final Proterozoic rise in atmospheric oxygen, which heralded the evolution of skeletonizing metazoans (Knoll and Carroll 1999) and the most dramatic diversification of Earth’s mineral inventory since the GOE.
Stage 10—The rise of skeletal biomineralization.
By the beginning of the Phanerozoic Eon (0.542 Ga) biology dominated Earth’s carbon mineralogy.
The early Cambrian Period witnessed an abrupt increase in all major skeletal minerals (Runnegar 1987; Knoll 2003), including the carbonate minerals calcite, aragonite, and magnesian calcite, which are precipitated by numerous algal and animal phyla, and are volumetrically the most significant biominerals.
In the early Paleozoic Era, however, non-enzymatic production of carbonate such as microbial carbonate (Riding 2002) continued to dominate over skeletal carbonate.
In fact, enzymatic skeletal carbonate production in the Cambrian composes < 5% of the volume of marine carbonate (Pruss et al.
2010).
It was not until after the Great Ordovician Biodiversification Event (GOBE; Harper 2006; Servais et al.
2009) that skeletal carbonate exceeded 15% of the volume of marine carbonate (Pruss et al.
2010).
Several lines of evidence suggest that changes in Earth’s ocean chemistry may have played a fundamental role in the transition from non-enzymatic to enzymatic carbonate deposition.
Microbial carbonate production, for instance, is controlled primarily by a combination of ambient carbonate saturation state, the availability of aqueous CO2 and HCO3, and pH changes within the microbial sheath in response to the photosynthetic uptake of CO2 and the conversion of HCO3 to CO2 via biological carbon concentrating mechanisms (Merz 1992; Arp et al.
2001; Riding and Liang 2005).
A dramatic decline in microbial carbonate production in the early Paleozoic Era (Riding 2006a,b) suggests a response in surface waters to a global decrease in pCO2 and marine carbonate saturation.
Alternatively, it has been suggested that deep-ocean anoxia and the increased anaerobic cycling of organic carbon (Fischer et al.
2007; Higgins et al.
2009) may have reduced marine carbonate saturation in the early Paleozoic Era to a point at which enzymatic production of skeletal carbonate may have been prohibitively high (Pruss et al.
2010).
In yet another model, the biological diversification of skeletonizing metazoans may have been inhibited prior to the late Middle Ordovician by deep-ocean anoxia that sequestered bioessential elements, thereby limiting nutrient sources for metazoans that rely on planktonic productivity (Servais et al.
2009).
In this scenario, a sustained increase in skeletonizing metazoans could not have occurred prior to deep ocean ventilation and reduction of dysoxic to anoxic deep waters in the late Middle Ordovician (cf.
Thompson and Kah 2012).
The complexity of a world that contains both enzymatic and non-enzymatic carbonate production is further illustrated by the biological and temporal variability in the mineralogy of calcium carbonate precipitated by corals, mollusks, and other invertebrates (Harper et al.
1997; Knoll 2003; Cohen and McConnaughey 2003; Palmer and Wilson 2004).
Not only are specific carbonate minerals commonly associated with distinct groups of organisms (Lowenstam and Weiner 1989; Simkiss and Wilbur 1989), but organisms themselves can contain numerous different carbonate minerals, such as the remarkable example of the biological adaptation of magnesium carbonate in lenses of some phacopid trilobites with compound eyes (Figure 5).
Each lens is a single crystal of calcite with the hexagonal c-axes precisely oriented perpendicular to the lens.
Furthermore, each lens is radially zoned with variable Mg/Ca to correct for chromatic aberration (Clarkson and Levi-Setti 1975; Lee et al.
2007).
The Phanerozoic rock record also preserved a series of temporal transitions in carbonate mineralogy.
Calcite mineralization dominates the fossil record from the early Cambrian Period through the early Carboniferous Period (~540 to 300 Ma), but a dramatic and rather sudden shift to increased aragonite biomineralization is observed in fossils from the mid-Mississippian Period through the mid-Jurassic Period (~300 to 150 Ma).
Calcite again became the dominant biocarbonate after the mid-Jurassic until approximately 35 million years ago, when aragonite biomineralization once again became common.
The origin of these so-called “calcite-aragonite sea” intervals remains controversial.
Because temporal variation in the abundance of calcite and aragonite mineralogies is observed in both skeletal and non-skeletal carbonates (Sandberg 1983, 1985; Wilkinson and Givens 1986), it is generally agreed that these temporal variations reflect global-scale changes in ocean chemistry.
Additional correlation between “calcite-aragonite sea” intervals and the Mg/Ca concentration of marine minerals (Hardie 1996) suggests that marine Mg/Ca ratio (Mg/Ca < 2 favoring calcite; Mg/Ca > 2 favoring magnesian-calcite and aragonite) may play a primary role in this mineralogical transition.
Marine Mg/Ca ratio may also have substantial influence on the production of skeletal calcite versus arragonite.
Stanley and Hardie (1998) showed that calcite-producing organisms are dominant components of the ecosystem during “calcite sea” intervals, and vice versa, which might reflect the differential stability of mineralogical phases, more robust mineralization of skeletons in thermodynamic stability with the ocean (Ries 2010), or even an evolutionary favorability within organisms whose skeletons are in equilibrium with the surrounding ocean (Porter 2007).
The interplay between ocean chemistry, biology, and carbonate mineralogy has continued through the Phanerozoic Eon.
The evolution of planktonic calcifying organisms in the Mesozoic Era marked the first time in Earth’s history when deep-ocean carbonate deposition was comparable to that of epicontinental environments (Ridgwell 2005).
Widespread deposition of carbonate from planktic organisms not only buffers the isotopic composition of the marine carbonate system (Bartley and Kah 2004; Ridgwell and Zeebe 2005), but may also buffer the global exchange of CO2 to an extent that future snowball events—such as that experienced by Earth in the late Neoproterozoic Era—would be impossible (Ridgwell et al.
2003).
In addition to the abundant and critically important carbonate minerals, Phanerozoic carbon mineralogy is enhanced by dozens of organic minerals (see Table 7 in Hazen et al.
2013), which have been identified from coal, black shales, oil shales, guano and other cave deposits, decayed wood, cacti, and other carbon-rich sources.
Biologically-derived organic molecular minerals include the remarkable Ni-porphyrin abelsonite (Ni2+C31H32N4), the purine uricite (C5H4N4O3), several hydrocarbons ranging in size from kratochvilite (C13H10) to evenkite (C24H48).
More than two-dozen minerals with organic anions, notably oxalate (C2O4)2- are also known from Phanerozoic deposits.
CONCLUSIONS: UNRESOLVED QUESTIONS IN CARBON MINERAL EVOLUTION
Much remains to be learned about the mineral evolution of carbon minerals, particularly with respect to carbonate mineral evolution.
Rhombohedral Mg-Ca-Fe-Mn carbonates are present in sedimentary, igneous, and metamorphic rocks throughout Earth history, but the paragenetic modes, production rates, and depositional environments of these carbonates have changed significantly.
For example, biologically mediated Phanerozoic deposition of carbonates must play a significant, though as yet unresolved, role in the changing global carbon cycle through time.
In particular, the onset of massive deposition of global platform carbonates from the Mesozoic Era, coupled with a gradually cooling geotherm and consequent stabilization of carbonates in subduction environments, must be altering the impact of subduction-mediated sequestration of carbon.
The possibly significant long-term consequences to the global carbon cycle are not known.
Other aspects of carbon mineral evolution relate to (1) the incorporation of numerous trace and minor elements, including a variety of redox sensitive elements, into rhombohedral carbonates; (2) isotopic variation in carbon and other elements; and (3) temporal changes in the morphology of carbonates, especially the richly varied crystal forms of calcite.
Each of these aspects of carbon mineralogy hold the potential to reveal much about the co-evolution of the geosphere and biosphere.
It is also intriguing to speculate on the carbon mineral evolution of other planets and moons.
In our solar system Titan presents an especially intriguing case.
At surface temperatures < 100 K, and with a near-surface composition dominated by hydrocarbons, Titan features lakes of liquid methane and possibly ethane.
In such an environment higher hydrocarbons become likely mineral phases.
For example, Glein (2012) has proposed that acetylene could be a common evaporate mineral along the shores of Titan’s hydrocarbon lakes.
Similar mineralogical oddities might dominate on planets in other star systems with very different metallicity, for example with significantly greater C/O (Bond et al.
2008, 2010; Carter-Bond et al.
2012; Michael Pagano, personal communication).
In such a system hydrocarbons, carbides, and organo-silanes might dominate relative to carbonate minerals.
In the extreme case, a carbon-rich planet might be dominated by graphite and diamond (Madhusudhan et al.
2012).
We conclude that the detailed study of carbon-bearing minerals through deep time can provide an unparalleled window into the tectonic, geochemical, and biological evolution of any terrestrial planet or moon.
Figure 1.
The presence of abundant Fe2+ in near-surface environments of the Archean Eon resulted in an effective hematite-magnetite buffer with fO2 at STP constrained to lie near 10-72.
Observations of redox sensitive uranium, sulfur, and europium species in Archean rocks are consistent with this value of fO2 (Hazen et al 2008; Sverjensky and Lee 2010).
Thermodynamic data used to construct this diagram came from the following sources: U-species (Shock et al.
1997a); all other aqueous species (Shock et al.
1997b); minerals (Helgeson et al.
1978).
Figure 2.
Ferrous iron carbonate stability requires log fO2 < -68 at STP, assuming log fCO2 < -2.
This value is consistent with the STP hematite-magnetite buffer of log fO2 ~ -72.
The lower dashed line in the diagram at log fO2 = -83.1 represents the lower stability of water at 1 atm H2.
Thermodynamic data used to construct this diagram came from the following sources: aqueous species (Shock et al.
1997b); minerals (Helgeson et al.
1978); the diagram was calculated with the aid of Geochemists Workbench (Bethke 1996).
Figure 3.
The stabilities of the copper carbonates azurite and malachite require log fO2 > -43 at STP, assuming log fCO2 < -2, which precludes their formation prior to the Great Oxidation Event.
Thermodynamic data used to construct this diagram came from the following sources: aqueous species (Shock et al.
1997b); Cu carbonate minerals (Preis & Gamsjäger 2002); Cu oxide minerals (Helgeson et al.
1978); the diagram was calculated with the aid of Geochemists Workbench (Bethke 1996).
Figure 4.
Differing morphologies of calcium carbonate are found in Mesoproterozoic strata and suggest that spatial variation in geochemical conditions may favor the abiotic precipitation of different carbonate minerals.
A) Fans and splays of hexagonal, acicular crystals with blunt terminations suggest neomorphic replacement of original aragonite.
B) Herringbone carbonate (here under crossed-polars) consists of elongate crystals, whose c-axis rotates from parallel to perpendicular to the elongated growth of the crystal.
It has been interpreted to reflect neomorphic recrystallization of spherulitic crystal clusters, with microdolomite inclusions, which suggest that the original mineralogy may have been magnesian-calcite.
C) Homogeneous crystal size distribution of molar-tooth calcite indicates precipitation through spontaneous nucleation and growth events, with limited Ostwald ripening.
Laboratory experiments suggest original depositional as amorphous calcium carbonate.
Long axis is is 2.6 mm in A, 1.37 mm in B, and 6.9 mm in C.
Figure 5.
The compound eyes (with “eye shade”) of the trilobite Erbenochile erbeni, as with other members of the order Phacopidae, incorporate single crystal lenses of calcite with the hexagonal c-axes precisely oriented perpendicular to the lens.
Furthermore, each lens is radially zoned with variable Mg/Ca to correct for chromatic aberration.
Photograph courtesy of Adam Aronson.
